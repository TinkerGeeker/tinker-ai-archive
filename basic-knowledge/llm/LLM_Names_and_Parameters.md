# 大模型名称参数


## 名称版本


### 厂商名称


#### 定义：标识模型研发或出品的厂商/品牌


#### 示例：qwen（通义千问厂商）、gemini（谷歌厂商）


### 版本信息


#### 定义：模型迭代更新的版本序列或代次


#### 示例：qwen3（通义千问 3 代）、deepseek V3.1（深度求索 V3.1）


### 发布日期


#### 定义：模型版本发布或更新的日期标识


#### 示例：Qwen3-4B-Instruct-2507（25年7月）


## 参数信息


### 绝对参数量


#### 定义：模型所有可训练参数的总和（如权重、偏置），单位为B或T


#### 示例：Qwen3-235B（2350 亿参数）


### 相对参数量


#### 定义：以相对尺度体现参数量级的标识（如nano、mini、medium）


#### 示例：gpt-4.1-mini（小量级参数）、mistral-medium（中量级）


### 激活参数量


#### 定义：动态架构（如 MoE）中单次推理实际参与计算的参数子集


#### 示例：Qwen3-30B-A3B（总参 300 亿，激活 30 亿，占比 10%）


## 性能分级


### 响应速度


#### 定义：模型生成回复的速率快慢（如fast、flash）


#### 示例：gemini-2.5-flash（快速响应）、grok-4-fast（高速）


### 模型能力


#### 定义：模型综合功能与性能的等级（如air、lite、plus、pro、max）


#### 示例：qwen3-plus（增强级）、gemini-2.5-pro（专业级）


## 量化部署


### 量化信息


#### 定义：模型量化精度、方法等压缩信息（如q4_0、8bit）


#### 示例：gemma-3-27b-it-q4_0（4bit 量化）


### 部署框架


#### 定义：模型适配的部署框架/格式（如mlx、onnx、gguf）


#### 示例：Llama-2-7b-chat-mlx（MLX 框架部署）
DeepSeek-R1-GGUF（llama.cpp、ollama部署）


## 其他主题


### 开源信息


#### 模型开源属性（gpt-oss-20b，oss开源）


### 专用场景


#### 模型针对的特定应用任务（datagemma-rag-27b-it（适配 RAG 场景））


### 语言支持


#### 模型主要适配或优化的语言种类（Llama3-8B-Chinese-Chat（中文））


### 上下文


#### 模型可处理的最大 token 长度（Phi-3-mini-128k）


### 全模态


#### 模型支持的多模态处理能力（gpt-4o-mini、o代表omni全模态）

